{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Accept-Reject Sampling**\n",
    "\n",
    "What if there is a distribution space with PDF $f(x)$ you want to sample from, but it is not feasible?\n",
    "\n",
    "Approximate a second distribution $g(x)$ that is *close* to your target distribution, and scale it (*M*) so that it is ≥ your target distribution (aiming at providing a good enough approximation).\n",
    "\n",
    "$$\n",
    "f(x) \\leq Mg(x)\n",
    "$$\n",
    "\n",
    "You **accept** that sample based on the probability of it also occurring in your target distribution (which should be closer to 1).\n",
    "\n",
    "$$\n",
    "p = \\frac{f(x)}{Mg(x)}\n",
    "$$\n",
    "\n",
    "Assume that there’s a sample that is very likely in your target distribution but is very unlikely in your proposal distribution distribution (ACCEPT). We might not see it again because we only see samples there are proposed by G and if this G is very low that we might not see the sample come up again.\n",
    "\n",
    "High values for this ratio indicate that this is a very important sample important because it’s rare to get proposed and also because it’s very high probability in our target distribution that thereby leads to very high probabilities of accept. \n",
    "\n",
    "### **Caveats**\n",
    "\n",
    "Choice of your estimator g is necessary, as real world distributions are usually even more complex. If we want to estimate that PDF using the normal distribution again we need to multiply the normal distribution by some big enough constant, so it’s always above this and that wouldn’t really be a problem except for if there is a “spike” in the curve, for example. \n",
    "\n",
    "This means that we may need to scale the normal distribution so much that it’s going to be above the spike what that means is that M is going to be huge because we need to multiply the normal distribution by a very large number to always be above and what does it mean if M is huge? The chance of accepting your estimated sample is low. So many of your samples fail to be resembling your target distribution, and they are inaccurate, hence rejected, and longer time taken to accept up until the sufficient amount of samples you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hoeffding's Inequality**\n",
    "\n",
    "$$\n",
    "P(|x-\\mu|>\\epsilon) \\leq 2e^{-2n\\epsilon}\n",
    "$$\n",
    "\n",
    "Set P to equal your confidence (e.g. 0.95). Then, solve for $\\epsilon$.\n",
    "\n",
    "E.g. for precision, recall, if you know the size of your test dataset, this is doable. (Substitute the value for n = len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Markov Chain from data**\n",
    "\n",
    "Below is a way to empirically estimate the transition matrix, given a dataset of flight data, recording the cities travelled (start destination, end destination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flight_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m F \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_cities, n_cities))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Step 3: Populate the frequency matrix\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mflight_data\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     40\u001b[0m     origin \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morigin_city\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     41\u001b[0m     destination \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdestination_city\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flight_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the flight data CSV\n",
    "# Example CSV format:\n",
    "\"\"\"\n",
    "origin_city,destination_city\n",
    "A,B\n",
    "A,C\n",
    "B,A\n",
    "...\n",
    "\"\"\"\n",
    "# flight_data = pd.read_csv(\"flight_data.csv\")\n",
    "\n",
    "# Dictionary of unique cities with their counts\n",
    "city_counts = {\n",
    "    \"A\": 3,\n",
    "    \"B\": 3,\n",
    "    \"C\": 2\n",
    "}\n",
    "\n",
    "# Step 1: Get the list of unique cities and create an index map\n",
    "unique_cities = list(city_counts.keys())\n",
    "\n",
    "#  NOTE: As the dict in Python is unstructured (lacking indexes),\n",
    "#  the following function makes a new dictionary that has the \n",
    "#  key-value pair: (unique city: index)\n",
    "\n",
    "# The index can be arbitrary, it is not necessary that, for ex. Rio De Janeiro is\n",
    "# index 2, it is based on when it occurs to the enumerator that goes through the \"cities\"\n",
    "# dict.\n",
    "city_to_index = {city: i for i, city in enumerate(unique_cities)}\n",
    "\n",
    "# Step 2: Initialize the frequency matrix F\n",
    "n_cities = len(unique_cities)\n",
    "F = np.zeros((n_cities, n_cities))\n",
    "\n",
    "# Step 3: Populate the frequency matrix\n",
    "for _, row in flight_data.iterrows():\n",
    "    origin = row[\"origin_city\"]\n",
    "    destination = row[\"destination_city\"]\n",
    "    \n",
    "    # Confirm that the city you are adding in the probability matrix is known\n",
    "    # by the cities dictionary, that has a list of recorded cities\n",
    "    if origin in city_to_index and destination in city_to_index:\n",
    "        i = city_to_index[origin] # the row index i - where we start\n",
    "        j = city_to_index[destination] # the column index j - destination\n",
    "        F[i, j] += 1\n",
    "\n",
    "# Step 4: Output the frequency matrix\n",
    "print(\"Frequency Matrix F:\")\n",
    "print(F)\n",
    "\n",
    "# FINAL STEP: Normalize the rows to get them between 0-1\n",
    "# As they are the probabilities\n",
    "# F at i,j in row i *divided by* sum of the values in row i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
